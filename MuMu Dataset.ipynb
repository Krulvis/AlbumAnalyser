{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "X_train = np.load(\"data/X_train_model_visual_MuMu-albums.npy\")\n",
    "Y_train = np.load(\"splits/y_train_class_250_MuMu-albums.npy\")\n",
    "\n",
    "X_test = np.load(\"data/X_test_model_visual_MuMu-albums.npy\")\n",
    "Y_test = np.load(\"splits/y_test_class_250_MuMu-albums.npy\")\n",
    "\n",
    "with open(\"splits/genre_labels_MuMu-albums.tsv\") as tsv:\n",
    "    genres = tsv.readlines()\n",
    "\n",
    "genres = [genre.strip() for genre in genres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25175, 2048)\n",
      "(3147, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "25175/25175 [==============================] - 9s 349us/step - loss: 26.6403 - acc: 0.0494\n",
      "Epoch 2/20\n",
      "25175/25175 [==============================] - 9s 338us/step - loss: 25.5224 - acc: 0.0533\n",
      "Epoch 3/20\n",
      "25175/25175 [==============================] - 8s 336us/step - loss: 25.3072 - acc: 0.0560\n",
      "Epoch 4/20\n",
      "25175/25175 [==============================] - 8s 335us/step - loss: 25.1543 - acc: 0.0540\n",
      "Epoch 5/20\n",
      "25175/25175 [==============================] - 9s 339us/step - loss: 25.0780 - acc: 0.0548\n",
      "Epoch 6/20\n",
      "25175/25175 [==============================] - 9s 358us/step - loss: 25.0021 - acc: 0.0551\n",
      "Epoch 7/20\n",
      "25175/25175 [==============================] - 9s 361us/step - loss: 24.9180 - acc: 0.0549\n",
      "Epoch 8/20\n",
      "25175/25175 [==============================] - 9s 353us/step - loss: 24.8717 - acc: 0.0535\n",
      "Epoch 9/20\n",
      "25175/25175 [==============================] - 9s 353us/step - loss: 24.8079 - acc: 0.0541\n",
      "Epoch 10/20\n",
      "25175/25175 [==============================] - 9s 353us/step - loss: 24.7611 - acc: 0.0553\n",
      "Epoch 11/20\n",
      "25175/25175 [==============================] - 9s 351us/step - loss: 24.7523 - acc: 0.0546\n",
      "Epoch 12/20\n",
      "25175/25175 [==============================] - 9s 355us/step - loss: 24.7170 - acc: 0.0549\n",
      "Epoch 13/20\n",
      "25175/25175 [==============================] - 9s 366us/step - loss: 24.6632 - acc: 0.0552\n",
      "Epoch 14/20\n",
      "25175/25175 [==============================] - 9s 355us/step - loss: 24.6489 - acc: 0.0553\n",
      "Epoch 15/20\n",
      "25175/25175 [==============================] - 9s 365us/step - loss: 24.5980 - acc: 0.0561\n",
      "Epoch 16/20\n",
      "25175/25175 [==============================] - 9s 369us/step - loss: 24.5810 - acc: 0.0559\n",
      "Epoch 17/20\n",
      "25175/25175 [==============================] - 9s 357us/step - loss: 24.5506 - acc: 0.0542\n",
      "Epoch 18/20\n",
      "25175/25175 [==============================] - 10s 408us/step - loss: 24.5366 - acc: 0.0545\n",
      "Epoch 19/20\n",
      "25175/25175 [==============================] - 9s 365us/step - loss: 24.4991 - acc: 0.0553\n",
      "Epoch 20/20\n",
      "25175/25175 [==============================] - 9s 362us/step - loss: 24.4903 - acc: 0.0555\n",
      "3147/3147 [==============================] - 0s 133us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "n_classes = 250\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# Model has an input_dimension of 1000 (all the words)\n",
    "model.add(Dense(2048, activation='relu', input_dim=2048))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.592627895325375"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
